{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.applications import EfficientNetB3\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "data_path = 'chest_xray/data'\n",
    "def oversampler(class_name, class_count):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    curr_dir = data_path + '/' + class_name\n",
    "    save_dir = curr_dir\n",
    "    images = os.listdir(curr_dir)\n",
    "    img = plt.imread(curr_dir + '/' + random.choice(images))\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "\n",
    "    cnt = class_count\n",
    "    target = 3500\n",
    "    for batch in datagen.flow(img, batch_size=1, save_to_dir=save_dir, save_prefix='aug', save_format='jpg'):\n",
    "        cnt += 1\n",
    "        img = plt.imread(curr_dir + '/' + random.choice(images))\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        if cnt >= target:\n",
    "            break\n",
    "\n",
    "def undersampler(class_name, class_count):\n",
    "    target_count = 3500\n",
    "    curr_dir = data_path + '/' + class_name\n",
    "    images = os.listdir(curr_dir)\n",
    "    images_to_delete = random.sample(images, class_count - target_count)\n",
    "    for image in images_to_delete:\n",
    "        img_path = os.path.join(curr_dir, image)\n",
    "        os.remove(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal 3500\n",
      "Pneu 3500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "classes = os.listdir('chest_xray/data')\n",
    "class_counts = [len(os.listdir('chest_xray/data/' + x)) for x in classes]\n",
    "for i in range(len(classes)):\n",
    "    print(classes[i], class_counts[i])\n",
    "    undersampler(classes[i], class_counts[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "train_path = \"train\"\n",
    "val_path = \"val\"\n",
    "test_path = \"test\"\n",
    "\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(val_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "train_ratio = 0.7  # 70% for training\n",
    "val_ratio = 0.15   # 15% for validation\n",
    "test_ratio = 0.15  # 15% for testing\n",
    "\n",
    "for class_folder in os.listdir(data_path):\n",
    "    class_path = os.path.join(data_path, class_folder)\n",
    "    \n",
    "    train_class_path = os.path.join(train_path, class_folder)\n",
    "    val_class_path = os.path.join(val_path, class_folder)\n",
    "    test_class_path = os.path.join(test_path, class_folder)\n",
    "    \n",
    "    os.makedirs(train_class_path, exist_ok=True)\n",
    "    os.makedirs(val_class_path, exist_ok=True)\n",
    "    os.makedirs(test_class_path, exist_ok=True)   \n",
    "    images = os.listdir(class_path)\n",
    "    random.shuffle(images)\n",
    "    num_images = len(images)\n",
    "    num_train = int(num_images * train_ratio)\n",
    "    num_val = int(num_images * val_ratio)\n",
    "    num_test = num_images - num_train - num_val\n",
    "    \n",
    "    train_images = images[:num_train]\n",
    "    val_images = images[num_train:num_train+num_val]\n",
    "    test_images = images[num_train+num_val:]\n",
    "    \n",
    "    for image in train_images:\n",
    "        shutil.copy(os.path.join(class_path, image), os.path.join(train_class_path, image))\n",
    "    \n",
    "    for image in val_images:\n",
    "        shutil.copy(os.path.join(class_path, image), os.path.join(val_class_path, image))\n",
    "    \n",
    "    for image in test_images:\n",
    "        shutil.copy(os.path.join(class_path, image), os.path.join(test_class_path, image))\n",
    "\n",
    "print(\"Dataset split completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4900 files belonging to 2 classes.\n",
      "Found 1050 files belonging to 2 classes.\n",
      "Found 1050 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import image_dataset_from_directory\n",
    "val_dir = \"val\"\n",
    "train_dir = \"train\"\n",
    "test_dir = 'test'\n",
    "train_path = \"train\"\n",
    "val_path = \"val\"\n",
    "test_path = \"test\"\n",
    "image_size = (256, 256)\n",
    "batch_size = 32\n",
    "# Define ImageDataGenerators for loading and preprocessing the data\n",
    "\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_path,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=123\n",
    ")\n",
    "class_names = train_dataset.class_names\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    val_path,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_path,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB3(weights=\"imagenet\",include_top=False,input_shape=(256,256,3))\n",
    "base_model.trainable=False\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "feature_extractor=Model(inputs=base_model.input,outputs=x)\n",
    "\n",
    "feature_shape=feature_extractor.output_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.efficientnet import preprocess_input\n",
    "def extract_features(dataset):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for batch, label_batch in dataset:\n",
    "        # Preprocess the images\n",
    "        batch = preprocess_input(batch)\n",
    "        # Extract features using EfficientNetB3\n",
    "        feature_batch = base_model(batch)\n",
    "        feature_batch = tf.reshape(feature_batch, (feature_batch.shape[0], -1))\n",
    "        features.append(feature_batch.numpy())\n",
    "        labels.append(label_batch.numpy())\n",
    "    return np.concatenate(features), np.concatenate(labels)\n",
    "\n",
    "# Extract features and labels for the training and validation datasets\n",
    "train_features, train_labels = extract_features(train_dataset)\n",
    "test_features, test_labels = extract_features(test_dataset)\n",
    "val_features, val_labels = extract_features(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten train_features and val_features\n",
    "train_features = train_features.reshape(train_features.shape[0], -1)\n",
    "val_features = val_features.reshape(val_features.shape[0], -1)\n",
    "\n",
    "# Ensure labels are 1D\n",
    "# train_labels = np.argmax(train_labels, axis=1)\n",
    "# val_labels = np.argmax(val_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9657142857142857\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest\n",
    "import joblib\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(train_features, train_labels)\n",
    "joblib.dump(rf_classifier, 'random_forest_model.pkl')\n",
    "\n",
    "# Validate Random Forest\n",
    "val_pred = rf_classifier.predict(val_features)\n",
    "print(f'Validation Accuracy: {accuracy_score(val_labels, val_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9752380952380952\n"
     ]
    }
   ],
   "source": [
    "test_pred = rf_classifier.predict(test_features)\n",
    "print(f'Validation Accuracy: {accuracy_score(test_labels, test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 5))\n",
    "cm = confusion_matrix(test_labels, test_pred)\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "disp.plot(ax=ax, colorbar=False, cmap='YlGnBu')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.98      0.98      0.98       525\n",
      "   Pneumonia       0.98      0.98      0.98       525\n",
      "\n",
      "    accuracy                           0.98      1050\n",
      "   macro avg       0.98      0.98      0.98      1050\n",
      "weighted avg       0.98      0.98      0.98      1050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = classification_report(test_labels, test_pred, target_names=['Normal', 'Pneumonia'])\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
